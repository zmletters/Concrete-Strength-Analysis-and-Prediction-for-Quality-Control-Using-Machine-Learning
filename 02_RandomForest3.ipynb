{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# --- 1. LOAD DATA ---\n",
    "df_kaggle = pd.read_csv(\"Data/zainfaisal_pakistan_concrete_data.csv\")\n",
    "df_local = pd.read_csv(\"Data/localdataset.csv\")\n",
    "\n",
    "# --- 3. HELPER FUNCTION (Standard Random Forest) ---\n",
    "def train_helper_data(df):\n",
    "    recipe_cols = ['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', \n",
    "                   'Superplasticizer', 'Coarse Aggregate', 'Fine Aggregate']\n",
    "    df.columns = df.columns.str.strip() \n",
    "    \n",
    "    # Train Helper\n",
    "    df_7 = df[df['Age'] == 7].copy()\n",
    "    X_helper = df_7[recipe_cols]\n",
    "    y_helper = df_7['Strength']\n",
    "    \n",
    "    helper_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    helper_model.fit(X_helper, y_helper)\n",
    "\n",
    "    # Impute\n",
    "    df_28 = df[df['Age'] == 28].copy()\n",
    "    df_28['Predicted_Strength_7'] = helper_model.predict(df_28[recipe_cols])\n",
    "    \n",
    "    df_7_grouped = df_7.groupby(recipe_cols)['Strength'].mean().reset_index()\n",
    "    df_7_grouped = df_7_grouped.rename(columns={'Strength': 'Real_Strength_7'})\n",
    "    \n",
    "    df_augmented = pd.merge(df_28, df_7_grouped, on=recipe_cols, how='left')\n",
    "    df_augmented['Strength_7'] = df_augmented['Real_Strength_7'].fillna(df_augmented['Predicted_Strength_7'])\n",
    "    \n",
    "    final_dataset = df_augmented[['Strength_7', 'Strength']].copy().rename(columns={'Strength': 'Strength_28'})\n",
    "    return final_dataset\n",
    "\n",
    "# --- 4. WEAKENED RANDOM FOREST PIPELINE ---\n",
    "def process_weakened_random_forest(df_helper, df_local):\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"   TUNING WEAKENED RANDOM FOREST\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # A. TRAIN BASE MODEL (The \"Lab Curve\")\n",
    "    print(\"1. Training Base Model...\")\n",
    "    X_base = df_helper[['Strength_7']]\n",
    "    y_base = df_helper['Strength_28']\n",
    "    \n",
    "    X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_base, y_base, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Base model can remain standard (it learns physics, which are stable)\n",
    "    base_model = RandomForestRegressor(n_estimators=200, max_depth=5, random_state=42)\n",
    "    base_model.fit(X_train_b, y_train_b)\n",
    "    \n",
    "    base_preds = base_model.predict(X_test_b)\n",
    "    print(f\"   > Base Model MAE: {mean_absolute_error(y_test_b, base_preds):.2f} MPa\")\n",
    "\n",
    "    # B. TRAIN CORRECTION MODEL (The part we want to WEAKEN)\n",
    "    print(\"\\n2. Training Correction Model (Temp + Rainfall)...\")\n",
    "    \n",
    "    df_local['Base_Pred_Lab'] = base_model.predict(df_local[['Strength_7']])\n",
    "    df_local['Residual'] = df_local['Strength_28'] - df_local['Base_Pred_Lab']\n",
    "    \n",
    "    X_corr = df_local[['avgTemp', 'Rainfall_Code']]\n",
    "    y_corr = df_local['Residual']\n",
    "    \n",
    "    X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_corr, y_corr, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # --- HERE IS THE WEAKENING STRATEGY ---\n",
    "    # We force the model to be very simple\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [1, 2],         # Very shallow trees (simpler rules)\n",
    "        'min_samples_leaf': [10, 15, 20], # Requires many samples to make a decision (ignores outliers)\n",
    "        'max_samples': [0.5, 0.7]    # Only look at 50-70% of data per tree (adds randomness)\n",
    "    }\n",
    "    \n",
    "    print(\"   > Running Grid Search to find constrained parameters...\")\n",
    "    rf_search = GridSearchCV(\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_search.fit(X_train_c, y_train_c)\n",
    "    \n",
    "    correction_model = rf_search.best_estimator_\n",
    "    print(f\"   > Best Settings Found: {rf_search.best_params_}\")\n",
    "\n",
    "    # C. FINAL VALIDATION\n",
    "    print(\"\\n3. Validating Full System...\")\n",
    "    \n",
    "    test_inputs_base = df_local.loc[X_test_c.index, ['Strength_7']]\n",
    "    pred_base_part = base_model.predict(test_inputs_base)\n",
    "    \n",
    "    test_inputs_corr = X_test_c\n",
    "    pred_corr_part = correction_model.predict(test_inputs_corr)\n",
    "    \n",
    "    final_predictions = pred_base_part + pred_corr_part\n",
    "    actual_values = df_local.loc[X_test_c.index, 'Strength_28']\n",
    "    \n",
    "    final_mae = mean_absolute_error(actual_values, final_predictions)\n",
    "    \n",
    "    print(f\"   > FINAL MAE: {final_mae:.2f} MPa\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(actual_values, final_predictions, color='green', alpha=0.6, label='Weakened RF Preds')\n",
    "    min_val = min(min(actual_values), min(final_predictions))\n",
    "    max_val = max(max(actual_values), max(final_predictions))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Match')\n",
    "    plt.xlabel(\"Actual Strength (MPa)\")\n",
    "    plt.ylabel(\"Predicted Strength (MPa)\")\n",
    "    plt.title(f\"Weakened Random Forest (MAE={final_mae:.2f})\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return base_model, correction_model\n",
    "\n",
    "# --- 5. EXECUTE ---\n",
    "df_helper = train_helper_data(df_kaggle)\n",
    "base_model_rf, correction_model_rf = process_weakened_random_forest(df_helper, df_local)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
