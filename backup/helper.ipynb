{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f4fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Training Helper Model (Ingredients -> 7-Day Strength) ---\n",
      "Helper Model Trained on 126 rows.\n",
      "Helper Accuracy (MAE): 1.71 MPa (Internal check)\n",
      "\n",
      "--- Step 2: Imputing Missing 7-Day Data ---\n",
      "\n",
      "--- DATASET EXPANSION RESULTS ---\n",
      "Original Pairs Found: 123\n",
      "New Synthetic Pairs:  302\n",
      "TOTAL TRAINING DATA:  425 pairs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(\"Data/zainfaisal_pakistan_concrete_data.csv\")\n",
    "\n",
    "# 1. DEFINE INGREDIENTS (Features for the Helper Model)\n",
    "recipe_cols = [\n",
    "    'Cement', 'Blast Furnace Slag', 'Fly Ash', \n",
    "    'Water', 'Superplasticizer', \n",
    "    'Coarse Aggregate', 'Fine Aggregate'\n",
    "]\n",
    "\n",
    "# Clean up column names just in case\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# --- STEP 1: TRAIN THE HELPER MODEL ---\n",
    "print(\"--- Step 1: Training Helper Model (Ingredients -> 7-Day Strength) ---\")\n",
    "\n",
    "# Filter for rows that actually have 7-day data\n",
    "df_7 = df[df['Age'] == 7].copy()\n",
    "\n",
    "if len(df_7) == 0:\n",
    "    print(\"CRITICAL ERROR: No 7-day data found in file to train the helper!\")\n",
    "else:\n",
    "    # Train the Helper Random Forest\n",
    "    X_helper = df_7[recipe_cols]\n",
    "    y_helper = df_7['Strength']\n",
    "    \n",
    "    helper_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    helper_model.fit(X_helper, y_helper)\n",
    "    \n",
    "    # Check accuracy of the helper itself\n",
    "    helper_acc = mean_absolute_error(y_helper, helper_model.predict(X_helper))\n",
    "    print(f\"Helper Model Trained on {len(df_7)} rows.\")\n",
    "    print(f\"Helper Accuracy (MAE): {helper_acc:.2f} MPa (Internal check)\")\n",
    "\n",
    "\n",
    "# --- STEP 2: PREPARE THE TARGET DATA (28-DAY ROWS) ---\n",
    "print(\"\\n--- Step 2: Imputing Missing 7-Day Data ---\")\n",
    "\n",
    "# Get all rows that are 28 days old (These are the ones we want to predict later)\n",
    "df_28 = df[df['Age'] == 28].copy()\n",
    "\n",
    "# We need to see if they already have a 7-day match (Real Pair)\n",
    "# or if we need to fake it (Synthetic Pair)\n",
    "\n",
    "# Strategy: We will predict 7-day strength for EVERY 28-day row first (Synthetic),\n",
    "# and then overwrite it with Real data if we find a match.\n",
    "\n",
    "# A. Generate Synthetic 7-Day Strength for ALL 28-day rows\n",
    "# (This predicts what the 7-day strength likely was based on the recipe)\n",
    "df_28['Predicted_Strength_7'] = helper_model.predict(df_28[recipe_cols])\n",
    "\n",
    "# B. Try to find Real Matches (Optional but recommended for accuracy)\n",
    "# We group by ingredients to handle the matching\n",
    "df_7_grouped = df_7.groupby(recipe_cols)['Strength'].mean().reset_index()\n",
    "df_7_grouped = df_7_grouped.rename(columns={'Strength': 'Real_Strength_7'})\n",
    "\n",
    "# Merge the real 7-day data onto the 28-day data\n",
    "# using the ingredients as the \"Key\"\n",
    "df_augmented = pd.merge(\n",
    "    df_28, \n",
    "    df_7_grouped, \n",
    "    on=recipe_cols, \n",
    "    how='left' # Keep all 28-day rows even if no match\n",
    ")\n",
    "\n",
    "# --- STEP 3: CREATE FINAL DATASET ---\n",
    "\n",
    "# Logic: Use Real_Strength_7 if it exists; otherwise use Predicted_Strength_7\n",
    "df_augmented['Strength_7'] = df_augmented['Real_Strength_7'].fillna(df_augmented['Predicted_Strength_7'])\n",
    "\n",
    "# Create a flag so you know which is which\n",
    "df_augmented['Type'] = np.where(df_augmented['Real_Strength_7'].notna(), 'Real Pair', 'Synthetic Pair')\n",
    "\n",
    "# Final Cleanup\n",
    "final_dataset = df_augmented[['Strength_7', 'Strength', 'Type']].copy()\n",
    "final_dataset = final_dataset.rename(columns={'Strength': 'Strength_28'})\n",
    "\n",
    "print(\"\\n--- DATASET EXPANSION RESULTS ---\")\n",
    "print(f\"Original Pairs Found: {len(df_augmented[df_augmented['Type'] == 'Real Pair'])}\")\n",
    "print(f\"New Synthetic Pairs:  {len(df_augmented[df_augmented['Type'] == 'Synthetic Pair'])}\")\n",
    "print(f\"TOTAL TRAINING DATA:  {len(final_dataset)} pairs\")\n",
    "\n",
    "# --- STEP 4: TRAIN YOUR MAIN MODEL ON THIS NEW DATA ---\n",
    "# Now you can proceed with Strategy 1 using 'final_dataset'\n",
    "# X = final_dataset[['Strength_7']]\n",
    "# y = final_dataset['Strength_28']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
